[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "Timeline\n\npraktikum-1: 1 Maret 2023, presensi ristek.link/presensi-sains-data-01\npraktikum-2: 8 Maret 2023, presensi ristek.link/presensi-sains-data-02\npraktikum-3: 15 Maret 2023, presensi ristek.link/presensi-sains-data-03\nTugas-1: 22 Maret 2023, tempat pengumpulan: bit.ly/Tugas1PrakSainsData\nTugas-2: 21 April 2023, tempat pengumpulan: https://ristek.link/tugas-sains-data-02\nTugas-3: 21 April 2023, tempat pengumpulan: https://ristek.link/tugas-sains-data-03"
  },
  {
    "objectID": "main-module/module-tahun-lalu.html",
    "href": "main-module/module-tahun-lalu.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "-Module 2021/2022-\nberikut ini adalah module pengajaran sains-data tahun 2021/2022. https://drive.google.com/open?id=1x2SR_L3pWH0W8Z0IUbL1ifBOcMSkWVYe&authuser=carlesoctavianus%40gmail.com&usp=drive_fs"
  },
  {
    "objectID": "main-module/week-01.html",
    "href": "main-module/week-01.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "Pada module ini kita akan coba mememahami package pandas, yang merupakan package inti dalam sains-data. kita akan coba melakukan beberapa transformasi data menggunakan pandas.\nsebelum itu, python module di bawah ini yang akan digunakan selama praktikum.\n\nimport numpy as np\nimport pandas as pd\n\n\n\n\npandas.Series sangat mirip dengan array NumPy (bahkan dibangun di atas objek array NumPy). Yang membedakan array NumPy dari sebuah Series adalah bahwa sebuah Series dapat memiliki label index, yang berarti dapat diindeks dengan label, bukan hanya lokasi nomor saja. Selain itu, sebuah Series tidak perlu menyimpan data numerik, ia dapat menyimpan objek Python sembarang.\n\n\nPaling mudah, ktia dapat membuat pd.Series dengan python list\n\nmy_index= ['a','b','c','d','e']\nmy_data= [1,2,3,4,5]\nmy_series= pd.Series(data=my_data, index=my_index)\n\n\nprint(my_series)\nprint(my_series.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n<class 'pandas.core.series.Series'>\n\n\n\n\n\nKita juga dapat membuat pd.Series dengan dictionary\n\n# creating a series from a dictionary\nmy_dict= {'a':1, 'b':2, 'c':3, 'd':4, 'e':5}\nmy_series_dict= pd.Series(my_dict)\n\n\nprint(my_series_dict)\nprint(my_series_dict.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n<class 'pandas.core.series.Series'>\n\n\n\n\n\n\n# Imaginary Sales Data for 1st and 2nd Quarters for Global Company\nq1 = {'Japan': 80, 'China': 450, 'India': 200, 'USA': 250}\nq2 = {'Brazil': 100,'China': 500, 'India': 210,'USA': 260}\n\n\n# Creating a Series from a Dictionary q1 and q2\nq1_series= pd.Series(q1)\nq2_series= pd.Series(q2)\n\n\nprint(q1_series)\n\nJapan     80\nChina    450\nIndia    200\nUSA      250\ndtype: int64\n\n\nKita dapat mengindeks dengan label\n\n# call values of q1_series based on named index\nprint(q1_series['Japan'])\nprint(q1_series['China'])\nprint(q1_series['India'])\n\n80\n450\n200\n\n\nkita dapat tetap dapat mengindeks dengan integer\n\n# u can also call values of q1_series based on positional index\nprint(q1_series[0])\nprint(q1_series[1])\nprint(q1_series[2])\n\n80\n450\n200\n\n\nhati-hati dalam melakukan indexing dengan label. bisa saja terjadi error jika label tidak ada di dalam pd.series\n\n# remember named index is case sensitive\ntry:\n    print(q1_series['japan'])\nexcept:\n    print('something went wrong')\n\nsomething went wrong\n\n\nOperasi aritmatik sederhana pada pd.Series bersifat broadcasting\n\n# operations with arithmetic on series are broadcasted to all values\nprint(q1_series*2)\n\nJapan    160\nChina    900\nIndia    400\nUSA      500\ndtype: int64\n\n\n\nprint(q1_series+1000)\n\nJapan    1080\nChina    1450\nIndia    1200\nUSA      1250\ndtype: int64\n\n\n\n# operation between series are also broadcasted\nprint(q1_series+q2_series)\n\nBrazil      NaN\nChina     950.0\nIndia     410.0\nJapan       NaN\nUSA       510.0\ndtype: float64\n\n\n\nprint(q1_series.add(q2_series, fill_value=0))\n\nBrazil    100.0\nChina     950.0\nIndia     410.0\nJapan      80.0\nUSA       510.0\ndtype: float64\n\n\n\n\n\n\nSebuah pd.DataFrame terdiri dari beberapa pd.Series yang berbagi nilai indeks.\n\nmy_data= np.random.randint(0,100,12).reshape(4,3)\nmy_data\n\narray([[25, 59, 18],\n       [75, 54, 65],\n       [29, 21,  7],\n       [32, 69, 16]])\n\n\nKita akan membuat pd.Dataframe melalui python list. Perhatikan bahwa kita dapat memberikan nama pada kolom dan baris\n\nmy_index= [\"jakarta\", \"bandung\", \"surabaya\", \"medan\"]\nmy_columns= [\"apple\", \"orange\", \"banana\"]\n\ndf= pd.DataFrame(data=my_data, index=my_index, columns=my_columns)\ndf\n\n\n\n\n\n  \n    \n      \n      apple\n      orange\n      banana\n    \n  \n  \n    \n      jakarta\n      25\n      59\n      18\n    \n    \n      bandung\n      75\n      54\n      65\n    \n    \n      surabaya\n      29\n      21\n      7\n    \n    \n      medan\n      32\n      69\n      16\n    \n  \n\n\n\n\n\ndf_2= pd.DataFrame(data=my_data)\ndf_2\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      25\n      59\n      18\n    \n    \n      1\n      75\n      54\n      65\n    \n    \n      2\n      29\n      21\n      7\n    \n    \n      3\n      32\n      69\n      16\n    \n  \n\n\n\n\n\ndf_3= pd.DataFrame(data=my_data, columns=my_columns)\ndf_3\n\n\n\n\n\n  \n    \n      \n      apple\n      orange\n      banana\n    \n  \n  \n    \n      0\n      25\n      59\n      18\n    \n    \n      1\n      75\n      54\n      65\n    \n    \n      2\n      29\n      21\n      7\n    \n    \n      3\n      32\n      69\n      16\n    \n  \n\n\n\n\n\n\nJika berkas .py atau .ipynb Anda berada di lokasi folder yang sama persis dengan berkas .csv yang ingin Anda baca, cukup berikan nama berkas sebagai string, misalnya:\ndf = pd.read_csv('[some_file.csv')\nBerikan s berkas jika Anda berada di direktori yang berbeda. Jalur berkas harus 100% benar agar ini berfungsi. Misalnya:\ndf = pd.read_csv(\"C:\\\\Users\\\\myself\\\\files\\\\some_file.csv\")\nsebelum itu, kalian dapat mendownload data tersebut melalui link berikut\nDownload\n\npwd\n\n'c:\\\\Users\\\\user\\\\Documents\\\\root\\\\personal\\\\github-personal\\\\sains-data-2023\\\\main-module'\n\n\n\ndf_tips= pd.read_csv('./data/tips.csv')\n\n\ndf_tips\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n      9.68\n      Michael Avila\n      5296068606052842\n      Sat2657\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n      13.59\n      Monica Sanders\n      3506806155565404\n      Sat1766\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n      11.34\n      Keith Wong\n      6011891618747196\n      Sat3880\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n      8.91\n      Dennis Dixon\n      4375220550950\n      Sat17\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n      9.39\n      Michelle Hardin\n      3511451626698139\n      Thur672\n    \n  \n\n244 rows × 11 columns\n\n\n\n\n\n\n\n# mengecek nama kolom\ndf_tips.columns\n\nIndex(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size',\n       'price_per_person', 'Payer Name', 'CC Number', 'Payment ID'],\n      dtype='object')\n\n\n\n# mengecek \ndf_tips.index\n\nRangeIndex(start=0, stop=244, step=1)\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\ndf_tips.tail(5)\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n      9.68\n      Michael Avila\n      5296068606052842\n      Sat2657\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n      13.59\n      Monica Sanders\n      3506806155565404\n      Sat1766\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n      11.34\n      Keith Wong\n      6011891618747196\n      Sat3880\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n      8.91\n      Dennis Dixon\n      4375220550950\n      Sat17\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n      9.39\n      Michelle Hardin\n      3511451626698139\n      Thur672\n    \n  \n\n\n\n\n\ndf_tips.describe().transpose()\n\n\n\n\n\n  \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n  \n  \n    \n      total_bill\n      244.0\n      1.978594e+01\n      8.902412e+00\n      3.070000e+00\n      1.334750e+01\n      1.779500e+01\n      2.412750e+01\n      5.081000e+01\n    \n    \n      tip\n      244.0\n      2.998279e+00\n      1.383638e+00\n      1.000000e+00\n      2.000000e+00\n      2.900000e+00\n      3.562500e+00\n      1.000000e+01\n    \n    \n      size\n      244.0\n      2.569672e+00\n      9.510998e-01\n      1.000000e+00\n      2.000000e+00\n      2.000000e+00\n      3.000000e+00\n      6.000000e+00\n    \n    \n      price_per_person\n      244.0\n      7.888197e+00\n      2.914234e+00\n      2.880000e+00\n      5.800000e+00\n      7.255000e+00\n      9.390000e+00\n      2.027000e+01\n    \n    \n      CC Number\n      244.0\n      2.563496e+15\n      2.369340e+15\n      6.040679e+10\n      3.040731e+13\n      3.525318e+15\n      4.553675e+15\n      6.596454e+15\n    \n  \n\n\n\n\n\n\n\n\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\nprint(df_tips[\"size\"] ==3)\nconditional_size = df_tips[\"size\"] ==3\n\n0      False\n1       True\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nName: size, Length: 244, dtype: bool\n\n\n\ndf_tips[conditional_size].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      16\n      10.33\n      1.67\n      Female\n      No\n      Sun\n      Dinner\n      3\n      3.44\n      Elizabeth Foster\n      4240025044626033\n      Sun9715\n    \n    \n      17\n      16.29\n      3.71\n      Male\n      No\n      Sun\n      Dinner\n      3\n      5.43\n      John Pittman\n      6521340257218708\n      Sun2998\n    \n    \n      18\n      16.97\n      3.50\n      Female\n      No\n      Sun\n      Dinner\n      3\n      5.66\n      Laura Martinez\n      30422275171379\n      Sun2789\n    \n  \n\n\n\n\n\nconditional= (df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]>20)\nprint(conditional)\n\n0      False\n1      False\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nLength: 244, dtype: bool\n\n\n\ndf_tips[conditional].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      19\n      20.65\n      3.35\n      Male\n      No\n      Sat\n      Dinner\n      3\n      6.88\n      Timothy Oneal\n      6568069240986485\n      Sat9213\n    \n    \n      35\n      24.06\n      3.60\n      Male\n      No\n      Sat\n      Dinner\n      3\n      8.02\n      Joseph Mullins\n      5519770449260299\n      Sat632\n    \n    \n      39\n      31.27\n      5.00\n      Male\n      No\n      Sat\n      Dinner\n      3\n      10.42\n      Mr. Brandon Berry\n      6011525851069856\n      Sat6373\n    \n    \n      48\n      28.55\n      2.05\n      Male\n      No\n      Sun\n      Dinner\n      3\n      9.52\n      Austin Fisher\n      6011481668986587\n      Sun4142\n    \n  \n\n\n\n\n\ndf_tips[(df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]>20)].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      19\n      20.65\n      3.35\n      Male\n      No\n      Sat\n      Dinner\n      3\n      6.88\n      Timothy Oneal\n      6568069240986485\n      Sat9213\n    \n    \n      35\n      24.06\n      3.60\n      Male\n      No\n      Sat\n      Dinner\n      3\n      8.02\n      Joseph Mullins\n      5519770449260299\n      Sat632\n    \n    \n      39\n      31.27\n      5.00\n      Male\n      No\n      Sat\n      Dinner\n      3\n      10.42\n      Mr. Brandon Berry\n      6011525851069856\n      Sat6373\n    \n    \n      48\n      28.55\n      2.05\n      Male\n      No\n      Sun\n      Dinner\n      3\n      9.52\n      Austin Fisher\n      6011481668986587\n      Sun4142\n    \n  \n\n\n\n\n\nweekend= [\"Sun\", \"Sat\"]\nconditional_in= df_tips[\"day\"].isin(weekend)\ndf_tips[conditional_in].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\ndf_tips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\n\n\n\ndf_tips[\"day\"].unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n\ndf_tips.drop_duplicates([\"day\",\"time\"])[[\"day\",\"time\"]]\n\n\n\n\n\n  \n    \n      \n      day\n      time\n    \n  \n  \n    \n      0\n      Sun\n      Dinner\n    \n    \n      19\n      Sat\n      Dinner\n    \n    \n      77\n      Thur\n      Lunch\n    \n    \n      90\n      Fri\n      Dinner\n    \n    \n      220\n      Fri\n      Lunch\n    \n    \n      243\n      Thur\n      Dinner\n    \n  \n\n\n\n\n\n\n\n\n\n\n\nprint(df_tips[\"day\"])\nprint(\"=======\")\nprint(df_tips.day)\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n=======\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n  \n    \n      \n      day\n      time\n    \n  \n  \n    \n      0\n      Sun\n      Dinner\n    \n    \n      1\n      Sun\n      Dinner\n    \n    \n      2\n      Sun\n      Dinner\n    \n    \n      3\n      Sun\n      Dinner\n    \n    \n      4\n      Sun\n      Dinner\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      239\n      Sat\n      Dinner\n    \n    \n      240\n      Sat\n      Dinner\n    \n    \n      241\n      Sat\n      Dinner\n    \n    \n      242\n      Sat\n      Dinner\n    \n    \n      243\n      Thur\n      Dinner\n    \n  \n\n244 rows × 2 columns\n\n\n\n\n\n\n\ndf_tips[\"tips_percentage\"]= df_tips[\"tip\"]/df_tips[\"total_bill\"]*100\n\ndf_tips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n      tips_percentage\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n      5.944673\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n      16.054159\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n      16.658734\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n      13.978041\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n      14.680765\n    \n  \n\n\n\n\n\n\n\n\ndf_tips.rename(columns={\"tips_percentage\":\"tips_percentage_%\"}, inplace=True)\ndf_tips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n      tips_percentage_%\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n      5.944673\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n      16.054159\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n      16.658734\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n      13.978041\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n      14.680765\n    \n  \n\n\n\n\n\n\n\n\n#relocate tips_percentage_% column to the rightmost\ncols= list(df_tips.columns)\ncols= [cols[-1]]+ cols[:-2]\n\ndf_tips= df_tips[cols]\n\n\ndf_tips\n\n\n\n\n\n  \n    \n      \n      tips_percentage_%\n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n    \n  \n  \n    \n      0\n      5.944673\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n    \n    \n      1\n      16.054159\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n    \n    \n      2\n      16.658734\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n    \n    \n      3\n      13.978041\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n    \n    \n      4\n      14.680765\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      20.392697\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n      9.68\n      Michael Avila\n      5296068606052842\n    \n    \n      240\n      7.358352\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n      13.59\n      Monica Sanders\n      3506806155565404\n    \n    \n      241\n      8.822232\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n      11.34\n      Keith Wong\n      6011891618747196\n    \n    \n      242\n      9.820426\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n      8.91\n      Dennis Dixon\n      4375220550950\n    \n    \n      243\n      15.974441\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n      9.39\n      Michelle Hardin\n      3511451626698139\n    \n  \n\n244 rows × 11 columns"
  },
  {
    "objectID": "main-module/week-02.html",
    "href": "main-module/week-02.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "Pada modul ini kita akan mempelajari beberapa cara untuk membuat visualisasi data menggunakan package Matplotlib dan Seaborn. Seaborn merupakan salah satu package visualisasi data yang sangat sering digunakan karena fleksibilitas dan banyaknya jenis plot yang disediakan.\n\n\n\n\nSebelum memulai, mari kita import terlebih dahulu module - module yang diperlukan.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\nPada module kali ini, akan digunakan tiga data csv yang berbeda untuk mempermudah kebutuhan visualisasi.\nKetiga data tersebut dapat kalian unduh pada tautan berikut: https://bit.ly/DataWeek2\n\nspotify_df = pd.read_csv('data/week 2/spotify.csv', index_col='Date', parse_dates=['Date'])\nflight_df = pd.read_csv('data/week 2/flight_delays.csv')\ninsurance_df = pd.read_csv('data/week 2/insurance.csv')\n\n\n\n\n\nSeperti yang sudah dipelajari pada Algoritma dan Pemrograman, visualisasi data dapat dilakukan dengan module matplotlib, antara lain untuk membuat line plot dan scatter plot.\nPertama, kita akan menggunakan data Spotify, yaitu data total daily streams 5 lagu hits pada masanya.\n\nspotify_df\n\n\n\n\n\n  \n    \n      \n      Shape of You\n      Despacito\n      Something Just Like This\n      HUMBLE.\n      Unforgettable\n    \n    \n      Date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2017-01-06\n      12287078\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-07\n      13190270\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-08\n      13099919\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-09\n      14506351\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-10\n      14275628\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2018-01-05\n      4492978\n      3450315.0\n      2408365.0\n      2685857.0\n      2869783.0\n    \n    \n      2018-01-06\n      4416476\n      3394284.0\n      2188035.0\n      2559044.0\n      2743748.0\n    \n    \n      2018-01-07\n      4009104\n      3020789.0\n      1908129.0\n      2350985.0\n      2441045.0\n    \n    \n      2018-01-08\n      4135505\n      2755266.0\n      2023251.0\n      2523265.0\n      2622693.0\n    \n    \n      2018-01-09\n      4168506\n      2791601.0\n      2058016.0\n      2727678.0\n      2627334.0\n    \n  \n\n366 rows × 5 columns\n\n\n\nBerikut adalah cara untuk membuat line plot pada satu fitur di dataframe menggunakan matplotlib\n\n\"\"\"\nMembuat line plot untuk lagu Shape of You menggunakan matplotlib\n\"\"\"\n\n# Mengatur besar figur plot\nplt.subplots(figsize=(8,6))\n\n# Membuat line plot\nplt.plot(spotify_df['Shape of You'], 'b')\n# Membuat label sumbu-x dan sumbu-y\nplt.xlabel('Date')\nplt.ylabel('Shape of You Total Daily Streams')\n# Menampilkan plot\nplt.show()\n\n\n\n\nApabila kita ingin menampilkan fitur-fitur lain dalam figur yang sama, kita dapat memanfaatkan loop\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan loop\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\n# Loop setiap nama kolom pada dataframe, lalu plot\nfor column in spotify_df.columns:\n    plt.plot(spotify_df[column])\n\nplt.legend(spotify_df.columns)\nplt.show()\n\n\n\n\nNamun, terdapat cara yang lebih mudah selain menggunakan looping. pandas dataframe memiliki method yang dapat secara langsung memvisualisasikan keseluruhan fiturnya, yaitu .plot().\nPada .plot() kita memiliki beberapa parameter yang dapat diatur, antara lain kind dan figsize. kind berfungsi untuk mengatur jenis plot yang ingin kita buat, sedangkan figsize berfungsi untuk mengatur besar figur yang dihasilkan.\nParameter lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan pandas .plot()\n\"\"\"\n\nspotify_df.plot(kind='line', figsize=(8,6))\nplt.xlabel('Date')\nplt.ylabel('Total Daily Streams')\nplt.show()\n\n\n\n\nSelain line plot, terdapat banyak macam kind yang bisa digunakan. Pada code cell dibawah terlihat bahwa pandas .plot() dapat menghasilkan histogram (perlu diperhatikan bahwa jenis plot perlu menyesuaikan tipe data yang dimiliki, terlihat bahwa menggunakan data spotify, histogram tidak menghasilkan insight yang cukup berguna).\n\nspotify_df.plot(kind='hist', figsize=(8,6), alpha=.7)\n\nplt.show()\n\n\n\n\nPada praktikum Algoritma dan Pemrograman kita juga telah mempelajari cara untuk membuat scatter plot. Berikut code untuk membuat scatter plot menggunakan matplotlib, untuk melihat korelasi antara daily streams lagu Shape of You dengan Something Just Like This.\n\n\"\"\"\nMembuat scatter plot untuk melihat korelasi antara lagu\nShape of You dengan Something Just Like This menggunakan\nmatplotlib\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\nplt.scatter(x=spotify_df['Shape of You'], \n            y=spotify_df['Something Just Like This'],\n            alpha=.5)\nplt.xlabel('\"Shape of You\" Total Daily Streams')\nplt.ylabel('\"Something Just Like This\" Total Daily Streams')\nplt.show()\n\n\n\n\n\n\n\nWalaupun matplotlib cukup fleksibel dalam menghasilkan plot, tetapi tipe plot yang disediakan cenderung terbatas. Oleh karena itu, kita dapat menggunakan Seaborn karena tipe plot yang disediakan sangat banyak sesuai kebutuhan kita, antara lain line, bar, heatmap, scatter, box, swarm, histogram, density, dan masih banyak lagi.\n\n\nLine plot biasa digunakan untuk melihat trend data dalam jangka waktu tertentu.\nUntuk membuat line plot pada seaborn, kita dapat menggunakan sns.lineplot(). Jika data yang ingin kita visualisasikan adalah dataframe, kita dapat memasukkan variabel dataframe tersebut pada parameter data, seperti code di bawah ini.\n\n\"\"\"\nMembuat line plot dengan module seaborn\n\"\"\"\n\nplt.subplots(figsize=(8,6))\nsns.lineplot(data=spotify_df)\nplt.show()\n\n\n\n\nFleksibilitas Seaborn membuat kita dapat memilih color palette yang sesuai dengan keinginan kita. Kita dapat memilih palette yang sudah disediakan oleh seaborn (antara lain: bright, deep, pastel, dan masih banyak lagi) atau kita dapat mengatur sendiri palette yang ingin kita gunakan.\nUntuk memilih palette yang akan digunakan untuk plot selanjutnya pada seaborn, kita dapat menggunakan sns.set_palette().\nJenis palette yang disediakan seaborn serta cara membuat color palette secara mandiri dapat dilihat pada: https://seaborn.pydata.org/tutorial/color_palettes.html#tools-for-choosing-color-palettes\n\n# Mengganti color palette menjadi \"bright\"\nsns.set_palette('bright')\n\n\n\"\"\"\nMembuat line plot setelah color palette diubah menjadi \"bright\"\n\"\"\"\n\n# Mengatur besar figur yang ingin ditampilkan\nplt.figure(figsize=(14,6))\n\n# Membuat line plot\nsns.lineplot(data=spotify_df)\n# Membuat judul figur\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\n# Menampilkan plot\nplt.show()\n\n\n\n\nApabila tidak semua fitur pada data ingin kita visualisasikan, kita dapat menggunakan sns.lineplot() beberapa kali, sesuai dengan banyaknya fitur yang ingin kita tampilkan, seperti pada code di bawah.\n\nplt.figure(figsize=(14,6))\n\n# Membuat line plot hanya dengan lagu Shape of You\nsns.lineplot(data=spotify_df['Shape of You'], label=\"Shape of You\")\n# Menambahkan line plot pada figur dengan lagu Despacito\nsns.lineplot(data=spotify_df['Despacito'], label=\"Despacito\")\n\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\nplt.xlabel(\"Date\")\nplt.ylabel('')\nplt.show()\n\n\n\n\n\n\n\nBar plot biasa digunakan untuk membandingkan kuantitas/nilai pada data bertipe kategori.\nSelanjutnya, kita akan menggunakan data flight_delays.csv, yaitu data rata-rata keterlambatan beberapa maskapai pesawat pada setiap bulannya.\n\nflight_df\n\n\n\n\n\n  \n    \n      \n      Month\n      AA\n      AS\n      B6\n      DL\n      EV\n      F9\n      HA\n      MQ\n      NK\n      OO\n      UA\n      US\n      VX\n      WN\n    \n  \n  \n    \n      0\n      1\n      6.955843\n      -0.320888\n      7.347281\n      -2.043847\n      8.537497\n      18.357238\n      3.512640\n      18.164974\n      11.398054\n      10.889894\n      6.352729\n      3.107457\n      1.420702\n      3.389466\n    \n    \n      1\n      2\n      7.530204\n      -0.782923\n      18.657673\n      5.614745\n      10.417236\n      27.424179\n      6.029967\n      21.301627\n      16.474466\n      9.588895\n      7.260662\n      7.114455\n      7.784410\n      3.501363\n    \n    \n      2\n      3\n      6.693587\n      -0.544731\n      10.741317\n      2.077965\n      6.730101\n      20.074855\n      3.468383\n      11.018418\n      10.039118\n      3.181693\n      4.892212\n      3.330787\n      5.348207\n      3.263341\n    \n    \n      3\n      4\n      4.931778\n      -3.009003\n      2.780105\n      0.083343\n      4.821253\n      12.640440\n      0.011022\n      5.131228\n      8.766224\n      3.223796\n      4.376092\n      2.660290\n      0.995507\n      2.996399\n    \n    \n      4\n      5\n      5.173878\n      -1.716398\n      -0.709019\n      0.149333\n      7.724290\n      13.007554\n      0.826426\n      5.466790\n      22.397347\n      4.141162\n      6.827695\n      0.681605\n      7.102021\n      5.680777\n    \n    \n      5\n      6\n      8.191017\n      -0.220621\n      5.047155\n      4.419594\n      13.952793\n      19.712951\n      0.882786\n      9.639323\n      35.561501\n      8.338477\n      16.932663\n      5.766296\n      5.779415\n      10.743462\n    \n    \n      6\n      7\n      3.870440\n      0.377408\n      5.841454\n      1.204862\n      6.926421\n      14.464543\n      2.001586\n      3.980289\n      14.352382\n      6.790333\n      10.262551\n      NaN\n      7.135773\n      10.504942\n    \n    \n      7\n      8\n      3.193907\n      2.503899\n      9.280950\n      0.653114\n      5.154422\n      9.175737\n      7.448029\n      1.896565\n      20.519018\n      5.606689\n      5.014041\n      NaN\n      5.106221\n      5.532108\n    \n    \n      8\n      9\n      -1.432732\n      -1.813800\n      3.539154\n      -3.703377\n      0.851062\n      0.978460\n      3.696915\n      -2.167268\n      8.000101\n      1.530896\n      -1.794265\n      NaN\n      0.070998\n      -1.336260\n    \n    \n      9\n      10\n      -0.580930\n      -2.993617\n      3.676787\n      -5.011516\n      2.303760\n      0.082127\n      0.467074\n      -3.735054\n      6.810736\n      1.750897\n      -2.456542\n      NaN\n      2.254278\n      -0.688851\n    \n    \n      10\n      11\n      0.772630\n      -1.916516\n      1.418299\n      -3.175414\n      4.415930\n      11.164527\n      -2.719894\n      0.220061\n      7.543881\n      4.925548\n      0.281064\n      NaN\n      0.116370\n      0.995684\n    \n    \n      11\n      12\n      4.149684\n      -1.846681\n      13.839290\n      2.504595\n      6.685176\n      9.346221\n      -1.706475\n      0.662486\n      12.733123\n      10.947612\n      7.012079\n      NaN\n      13.498720\n      6.720893\n    \n  \n\n\n\n\nUntuk membuat bar plot pada seaborn dengan dataframe, kita dapat menggunakan sns.barplot() dengan tiga parameter yang wajib kita set, yaitu:\n- data: dataframe yang ingin kita visualisasikan\n\n- x: nama fitur pada dataframe yang ingin kita jadikan sumbu-x\n\n- y: nama fitur pada dataframe yang ingin kita jadikan sumbu-y\nPada kode di bawah, juga digunakan satu parameter opsional, yaitu palette yang merupakan cara lain untuk mengatur color palette yang ingin kita gunakan\n\n\"\"\"\nMembuat bar plot keterlambatan maskapai EV setiap \nbulannya menggunakan seaborn\n\"\"\"\n\nplt.figure(figsize=(14,6))\n\nsns.barplot(data=flight_df, x='Month', y='EV',\n            palette=sns.color_palette('deep'))\nplt.ylabel('EV Flight Delays (minute)')\nplt.title('Average EV Flight Delays per Month')\nplt.show()\n\n\n\n\nBerdasarkan hasil plot di atas, terlihat bahwa maskapai EV memiliki rata-rata keterlambatan terlama pada bulan Juni, serta tercepat pada bulan September.\nSelanjutnya, mari kita coba lihat urutan rata-rata keterlambatan semua maskapai dalam satu tahun (maskapai mana yang memiliki rata-rata keterlambatan terlama, serta maskapai mana yang tercepat).\nHal pertama yang perlu kita lakukan adalah, jadikan fitur Month sebagai index dataframe.\n\n# Set fitur \"Month\" menjadi index dataframe\nflight_df = flight_df.set_index('Month')\nflight_df.head(2)\n\n\n\n\n\n  \n    \n      \n      AA\n      AS\n      B6\n      DL\n      EV\n      F9\n      HA\n      MQ\n      NK\n      OO\n      UA\n      US\n      VX\n      WN\n    \n    \n      Month\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      6.955843\n      -0.320888\n      7.347281\n      -2.043847\n      8.537497\n      18.357238\n      3.512640\n      18.164974\n      11.398054\n      10.889894\n      6.352729\n      3.107457\n      1.420702\n      3.389466\n    \n    \n      2\n      7.530204\n      -0.782923\n      18.657673\n      5.614745\n      10.417236\n      27.424179\n      6.029967\n      21.301627\n      16.474466\n      9.588895\n      7.260662\n      7.114455\n      7.784410\n      3.501363\n    \n  \n\n\n\n\nSelanjutnya, kita perlu hitung rata-rata keterlambatan tiap maskapai dalam satu tahun, yaitu hitung rata-rata tiap kolom pada dataframe menggunakan .mean() (Tambahan: apabila kita ingin menghitung rata-rata tiap barisnya, kita dapat menggunakan parameter axis=1 pada .mean()). .mean() akan menghasilkan pandas Series.\nLalu, agar mempermudah kita dalam melihat visualisasi bar plotnya, kita dapat menggunakan .sort_values().\n\n# Simpan rata-rata keterlambatan semua maskapai dalam satu tahun pada variabel flight_mean_inyear\nflight_mean_inyear = flight_df.mean()\n# Urutkan flight_mean_inyear secara ascending\nflight_mean_inyear = flight_mean_inyear.sort_values()\n\nflight_mean_inyear\n\nAS    -1.023656\nDL     0.231116\nHA     1.993205\nUS     3.776815\nAA     4.120776\nWN     4.275277\nVX     4.717718\nUA     5.413415\nOO     5.909658\nMQ     5.964953\nEV     6.543328\nB6     6.788370\nF9    13.035736\nNK    14.549663\ndtype: float64\n\n\nTerakhir, visualisasikan bar plot menggunakan cara seperti sebelumnya.\nKita dapat lihat pada code dibawah bahwa tidak digunakan parameter data, karena flight_mean_inyear merupakan pandas Series (bukan dataframe) sehingga lebih mudah jika kita langsung menggunakan parameter x dan y saja.\n\nplt.subplots(figsize=(14,6))\nsns.barplot(x=flight_mean_inyear.index, \n            y=flight_mean_inyear.values,\n            palette=sns.color_palette('deep'))\nplt.title('Average Delay per Flight in a Year')\nplt.show()\n\n\n\n\nBerdasarkan plot diatas, NK merupakan maskapai dengan rata-rata keterlambatan terlama dalam satu tahun, sedangkan AS adalah yang tercepat (AS bernilai negatif yang berarti rata-rata kedatangan pesawat lebih cepat dari yang dijadwalkan dalam satu tahun.\n\n\n\nHeatmap biasa digunakan untuk mempermudah melihat pola pada data berdasarkan warna yang dihasilkan.\nPada seaborn, kita dapat menggunakan heatmap dengan sns.heatmap() seperti pada kode dibawah. Parameter annot berfungsi untuk menampilkan nilai data (jika True) atau tidak (jika False).\nBar sebelah kanan heatmap menunjukkan bahwa, semakin lama keterlambatan pesawat, maka warna yang dihasilkan semakin terang. Sebaliknya, semakin gelap warna yang dihasilkan berarti semakin cepat pesawat datang tersebut.\n\n\"\"\"\nMembuat heatmap menggunakan Seaborn\n\"\"\"\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_df, annot=True)\nplt.title(\"Average Arrival Delay for Each Airline, by Month\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\nBerdasarkan heatmap di atas, kita dapat melihat dengan mudah pada bulan apa suatu maskapai sangat terlambat (contoh: maskapai NK pada bulan Juni).\nHeatmap sangat sering digunakan untuk melihat korelasi antarfitur pada dataset agar kita dapat mengerti lebih jauh tentang fitur-fitur pada data, atau juga dapat dimanfaatkan untuk melakukan feature selection sebelum membuat sebuat model Machine Learning.\nUntuk melakukan hal tersebut, kita perlu menghitung dahulu korelasi antar fitur menggunakan pandas .corr(), yaitu fungsi yang akan menghitung korelasi antar dua fitur menggunakan korelasi Pearson.\nNotes: Metode korelasi dapat diubah dengan menggunakan parameter method pada .corr(), contoh: .corr(method='spearman'). Metode lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n\n# Hitung korelasi antar dua fitur pada flight_df\nflight_corr = flight_df.corr()\n\nflight_corr\n\n\n\n\n\n  \n    \n      \n      AA\n      AS\n      B6\n      DL\n      EV\n      F9\n      HA\n      MQ\n      NK\n      OO\n      UA\n      US\n      VX\n      WN\n    \n  \n  \n    \n      AA\n      1.000000\n      0.334980\n      0.429854\n      0.805229\n      0.896523\n      0.903986\n      0.220065\n      0.842701\n      0.573716\n      0.620477\n      0.809874\n      0.823713\n      0.425237\n      0.615664\n    \n    \n      AS\n      0.334980\n      1.000000\n      0.340359\n      0.394359\n      0.356608\n      0.336791\n      0.684979\n      0.283977\n      0.480863\n      0.350657\n      0.457414\n      0.489025\n      0.229571\n      0.519228\n    \n    \n      B6\n      0.429854\n      0.340359\n      1.000000\n      0.643313\n      0.342627\n      0.510718\n      0.467905\n      0.529724\n      0.032038\n      0.591115\n      0.233021\n      0.788345\n      0.579750\n      0.151750\n    \n    \n      DL\n      0.805229\n      0.394359\n      0.643313\n      1.000000\n      0.796951\n      0.783265\n      0.262251\n      0.598765\n      0.625277\n      0.569073\n      0.797339\n      0.821757\n      0.700605\n      0.691805\n    \n    \n      EV\n      0.896523\n      0.356608\n      0.342627\n      0.796951\n      1.000000\n      0.828515\n      0.099369\n      0.721468\n      0.784026\n      0.692697\n      0.911499\n      0.669736\n      0.462638\n      0.730115\n    \n    \n      F9\n      0.903986\n      0.336791\n      0.510718\n      0.783265\n      0.828515\n      1.000000\n      0.273878\n      0.912984\n      0.414064\n      0.582509\n      0.671986\n      0.878874\n      0.308397\n      0.465765\n    \n    \n      HA\n      0.220065\n      0.684979\n      0.467905\n      0.262251\n      0.099369\n      0.273878\n      1.000000\n      0.436015\n      0.176485\n      0.056941\n      0.066821\n      0.586160\n      -0.008439\n      -0.007296\n    \n    \n      MQ\n      0.842701\n      0.283977\n      0.529724\n      0.598765\n      0.721468\n      0.912984\n      0.436015\n      1.000000\n      0.281890\n      0.586963\n      0.503575\n      0.660181\n      0.150111\n      0.239744\n    \n    \n      NK\n      0.573716\n      0.480863\n      0.032038\n      0.625277\n      0.784026\n      0.414064\n      0.176485\n      0.281890\n      1.000000\n      0.365273\n      0.827455\n      0.293515\n      0.395419\n      0.742869\n    \n    \n      OO\n      0.620477\n      0.350657\n      0.591115\n      0.569073\n      0.692697\n      0.582509\n      0.056941\n      0.586963\n      0.365273\n      1.000000\n      0.626051\n      0.590313\n      0.561515\n      0.548304\n    \n    \n      UA\n      0.809874\n      0.457414\n      0.233021\n      0.797339\n      0.911499\n      0.671986\n      0.066821\n      0.503575\n      0.827455\n      0.626051\n      1.000000\n      0.477816\n      0.536968\n      0.926800\n    \n    \n      US\n      0.823713\n      0.489025\n      0.788345\n      0.821757\n      0.669736\n      0.878874\n      0.586160\n      0.660181\n      0.293515\n      0.590313\n      0.477816\n      1.000000\n      0.333396\n      0.242344\n    \n    \n      VX\n      0.425237\n      0.229571\n      0.579750\n      0.700605\n      0.462638\n      0.308397\n      -0.008439\n      0.150111\n      0.395419\n      0.561515\n      0.536968\n      0.333396\n      1.000000\n      0.630278\n    \n    \n      WN\n      0.615664\n      0.519228\n      0.151750\n      0.691805\n      0.730115\n      0.465765\n      -0.007296\n      0.239744\n      0.742869\n      0.548304\n      0.926800\n      0.242344\n      0.630278\n      1.000000\n    \n  \n\n\n\n\nPandas .corr() menghasilkan dataframe dengan nama baris dan kolom yang sama, serta berisi nilai korelasi antara baris dan kolom yang ditinjau (contoh: korelasi antara maskapai AA dan AS adalah 0,334980). Serta, dataframe yang dihasilkan adalah sebuat matriks simetris.\nTentu dengan hanya melihat dataframe di atas, tidak terlihat begitu jelas mana fitur yang memiliki korelasi tinggi dan mana yang yang memiliki korelasi rendah. Oleh karena itu, kita dapat memanfaatkan heatmap.\nPada code di bawah, untuk mempermudah pembacaan heatmap, kita menggunakan parameter vmin, vmax, dan center pada sns.heatmap(). vmin berfungsi untuk mengatur nilai terendah, vmax berfungsi untuk mengatur nilai tertinggi, dan center berfungsi untuk mengatur nilai tengah pada heatmap. Korelasi Pearson menghasilkan nilai antara -1 hingga 1, sehingga kita dapat set ketiga parameter tersebut seperti pada code di bawah.\n\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_corr, vmin=-1, vmax=1, center=0, annot=True)\nplt.title(\"Pearson Correlation of Each Airline Flight Delays\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\nDengan menggunakan heatmap, sekarang terlihat bahwa mana maskapai yang keterlambatannya berkorelasi tinggi dan mana yang rendah. Misal, AA dan EV menghasilkan korelasi yang cukup tinggi positif, yaitu 0.9, yang artinya jika keterlambatan maskapai AA tinggi, begitu juga maskapai EV, dan sebaliknya jika keterlambatan maskapai AA rendah, begitu juga maskapai EV.\nUntuk meyakinkan kita dengan hal tersebut, kita dapat lihat pada materi selanjutnya, yaitu Scatter Plot.\n\n\n\nScatter plot biasa digunakan untuk melihat korelasi antara dua fitur bertipe numerik.\nUntuk menggunakan scatter plot pada seaborn, kita dapat menggunakan sns.scatterplot(), dengan parameter yang sama seperti kita membuat bar plot.\n\n\"\"\"\nMembuat scatter plot untuk melihat \nketerkaitan pada keterlambatan pesawat\nmaskapai EV dan AA\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='AA')\nplt.show()\n\n\n\n\nMelalui scatter plot di atas, kita dapat semakin yakin bahwa kesimpulan yang kita ambil dengan melihat heatmap sebelumnya benar.\n\n\"\"\"\nTambahan scatter plot pada maskapai lain yang\nmemiliki korelasi tinggi\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='UA')\nplt.show()\n\n\n\n\n\n\"\"\"\nScatter plot pada maskapai yang memiliki\nkorelasi rendah (mendekati 0)\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='UA', y='HA')\nplt.show()\n\n\n\n\nPada heatmap, terlihat bahwa maskapai UA dan HA memiliki korelasi yang rendah, yaitu 0.067. Sehingga, jika kita buat scatter plotnya, menghasilkan plot seperti di atas.\nUntuk memahami scatter plot lebih baik, kita akan menggunakan dataset lainnya, yaitu insurance.csv yang merupakan data berisi biaya asuransi (charges) beberapa orang.\n\ninsurance_df.head()\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      bmi\n      children\n      smoker\n      region\n      charges\n    \n  \n  \n    \n      0\n      19\n      female\n      27.900\n      0\n      yes\n      southwest\n      16884.92400\n    \n    \n      1\n      18\n      male\n      33.770\n      1\n      no\n      southeast\n      1725.55230\n    \n    \n      2\n      28\n      male\n      33.000\n      3\n      no\n      southeast\n      4449.46200\n    \n    \n      3\n      33\n      male\n      22.705\n      0\n      no\n      northwest\n      21984.47061\n    \n    \n      4\n      32\n      male\n      28.880\n      0\n      no\n      northwest\n      3866.85520\n    \n  \n\n\n\n\nMisal, kita ingin melihat keterkaitan indeks massa tubuh (bmi) seseorang dengan biaya asuransi (charges) orang tersebut. Sama seperti sebelumnya, kita dapat melakukannya seperti pada code di bawah.\n\n# Mengubah palette menjadi default\nsns.set_palette('tab10')\n# Membuat scatter plot antara fitur bmi dan charges\nsns.scatterplot(data=insurance_df, x='bmi', y='charges')\n\nplt.show()\n\n\n\n\nScatter plot di atas menunjukkan bahwa korelasi antara bmi dan charges adalah cenderung positif, tetapi tidak terlalu tinggi. Yang artinya, orang dengan BMI tinggi, cenderung akan membayar biaya asuransi lebih tinggi.\nAgar kita semakin yakin dengan kesimpulan tersebut, kita dapat menambahakn garis regresi pada scatter plot tersebut dengan menggunakan sns.regplot().\n\nsns.regplot(data=insurance_df, x='bmi', y='charges')\nplt.show()\n\n\n\n\nBerdasarkan scatter plot dan garis regresi dihasilkan, terlihat bahwa kesimpulan yang kita ambil benar. Agar semakin yakin lagi, kita juga dapat menghitung langsung korelasi Pearsonnya menggunakan cara sebelumnya, yaitu pandas .corr().\n\ninsurance_df[['bmi', 'charges']].corr()\n\n\n\n\n\n  \n    \n      \n      bmi\n      charges\n    \n  \n  \n    \n      bmi\n      1.000000\n      0.198341\n    \n    \n      charges\n      0.198341\n      1.000000\n    \n  \n\n\n\n\nDengan menggunakan seaborn, kita juga dapat memvisualisasikan scatter plot berdasarkan dengan pewarnaan yang berbeda berdasarkan fitur lainnya yang bertipe kategorik.\nMisal, kita ingin membuat scatter plot antara fitur bmi dan charges dengan pewarnaannya berdasarkan nilai dari fitur smoker, yaitu yes atau no. Kita dapat set parameter hue='smoker' pada sns.scatterplot() seperti pada code di bawah.\n\nsns.scatterplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\nSehingga dihasilkan pewarnaan yang berbeda untuk seseorang yang merupakan perokok (biru) dan yang tidak (orange). Berdasarkan scatter plot di atas, terlihat bahwa korelasi antara bmi dan charges untuk perokok cendering tinggi positif (semakin besar bmi, semakin besar juga charges). Sedangkan, untuk bukan perokok, korelasinya cenderung rendah (semakin besar bmi, tidak terlalu berpengaruh terhadap charges).\nSeperti cara sebelumnya, kita dapat menambahkan garis regresi. Namun, karena kita disini menggunakan hue, terdapat dua cara untuk menambahkan garis regresi, yaitu yang pertama adalah menggunakan sns.regplot() seperti di bawah ini.\n\nsns.regplot(data=insurance_df.query('smoker == \"yes\"'), x='bmi', y='charges') # axes 1\nsns.regplot(data=insurance_df.query('smoker == \"no\"'), x='bmi', y='charges') # axes 2\nplt.show()\n\n\n\n\nPerhatikan bahwa sns.regplot() dipanggil dua kali karena fungsi tersebut tidak memiliki parameter hue.\nUntuk mempermudah, kita dapat menggunakan cara kedua, yaitu menggunakan sns.lmplot(). Cara kerja sns.lmplot() yaitu menggabungkan dua (atau lebih) sns.regplot() dalam satu figur.\n\nsns.lmplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\nBox plot dan swarm plot biasa digunakan untuk melihat keterkaitan antara data kategorik dan data numerik. Swarm plot biasa disebut sebagai “categorical scatter plot”, karena plot yang dihasilkan mirip seperti scatter plot, tetapi untuk data kategorik.\nUntuk menggunakan box plot pada seaborn kita dapat menggunakan sns.boxplot().\nUntuk menggunakan swarm plot pada seaborn kita dapat menggunakan sns.swarmplot().\nMisal, kita ingin melihat keterkaitan antara fitur smoker dan charges menggunakan swarm plot. Maka, kita dapat menggunakan code seperti di bawah ini.\n\nplt.subplots(figsize=(10,6))\n\nsns.swarmplot(data=insurance_df, x='smoker', y='charges', size=3)\nplt.show()\n\n\n\n\nBerdasarkan swarm plot di atas, terlihat bahwa perokok cenderung memiliki biaya asuransi yang lebih tinggi dibandingkan yang bukan perokok. Selain itu, semakin lebar “swarm” pada suatu kategori berarti semakin banyak seseorang dengan nilai charges tersebut.\nApabila kita ingin menggunakan box plot, maka dapat digunakan code seperti di bawah ini.\n\nsns.boxplot(data=insurance_df, x='smoker', y='charges')\nplt.show()\n\n\n\n\nPada box plot, terdapat dua istilah yang umum digunakan, yaitu “box” dan “whiskers”. Pada box plot di atas, “box” merupakan persegi panjang berwarna biru dan orange. Garis di tengah box merupakan nilai mediannya, serta garis bawah dan garis atas box merupakan kuartil bawah (Q1) dan kuartil atas (Q3) secara berurutan. “Whiskers” adalah garis yang merupakan perpanjangan dari box. Ujung dari whiskers atas adalah Q3 + (1.5 x IQR) data, sedangkan ujung whiskers bawah adalah Q1 - (1.5 x IQR) data.\nTitik di luar box dan whiskers tersebut adalah titik yang biasa dijadikan sebagai outlier (penentuan outlier diserahkan ke diri masing-masing, apakah hanya dengan melihat box plot atau dengan menggunakan metode lain, tetapi untuk mempermudah dapat menggunakan box plot).\n\n\n\nSelain box plot dan swarm plot, kita juga dapat melihat persebaran data menggunakan histogram dan density plot. Histogram biasa digunakan untuk melihat persebaran data secara diskrit, sedangkan density plot untuk melihat persebaran data secara kontinu.\nUntuk membuat histogram pada seaborn, kita dapat menggunakan sns.histplot().\nUntuk membuat density plot pada seaborn, kita dapat menggunakan sns.kdeplot().\nMisal, kita ingin melihat persebaran dari fitur charges pada insurance_df. Maka dapat digunakan code seperti di bawah.\n\nplt.subplots(figsize=(12,6))\n\nsns.histplot(data=insurance_df, x='charges')\nplt.show()\n\n\n\n\nBerdasarkan histogram di atas, terlihat bahwa distribusi charges cenderung “skew” atau miring ke kanan. “Skewness” atau tingkat kecondongan merupakan aspek yang penting untuk diperhatikan ketika kita ingin membuat model Machine Learning.\nSeperti scatter plot, kita juga dapat menentukan pewarnaan histogram berdasarkan fitur lainnya dengan menggunakan parameter hue seperti di bawah ini/\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker')\nplt.show()\n\n\n\n\nJika ingin membuat density plot dari fitur charges, kita dapat menggunakan kode seperti di bawah ini. Parameter shade berfungsi untuk memberikan warna di bawah kurva.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges', shade=True)\nplt.show()\n\n\n\n\nsns.kdeplot() juga dapat menggunakan parameter hue.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges',\n            hue='smoker', shade=True)\nplt.show()\n\n\n\n\nApabila kita ingin menggabungkan histogram dan density plot dalam satu figur, kita dapat menggunakan sns.histplot() dengan parameter kde=True.\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker', kde=True)\nplt.show()\n\n\n\n\n\n\n\nPada seaborn, kita juga dapat membuat dua plot yang berbeda dari dua fitur dalam satu figur yang sama menggunakan sns.jointplot().\nJenis plot yang dihasilkan dapat diatur pada parameter kind. Pilihan jenis kind yang disediakan dapat dilihat pada: https://seaborn.pydata.org/generated/seaborn.jointplot.html\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"scatter\")\n\nplt.show()\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"hist\")\n\nplt.show()\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"kde\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nimage.png\n\n\nsource: https://www.kaggle.com/code/alexisbcook/choosing-plot-types-and-custom-styles"
  },
  {
    "objectID": "main-module/week-03.html",
    "href": "main-module/week-03.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "import library yang dibutuhkan terlebih dahulu untuk pengolahan dan visualisasi data.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n\n\nUpload dataset yang akan digunakan dan observasi click disini\n\nsalary =  pd.read_csv('Salary_dataset.csv')\nsalary\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      YearsExperience\n      Salary\n    \n  \n  \n    \n      0\n      0\n      1.2\n      39344.0\n    \n    \n      1\n      1\n      1.4\n      46206.0\n    \n    \n      2\n      2\n      1.6\n      37732.0\n    \n    \n      3\n      3\n      2.1\n      43526.0\n    \n    \n      4\n      4\n      2.3\n      39892.0\n    \n    \n      5\n      5\n      3.0\n      56643.0\n    \n    \n      6\n      6\n      3.1\n      60151.0\n    \n    \n      7\n      7\n      3.3\n      54446.0\n    \n    \n      8\n      8\n      3.3\n      64446.0\n    \n    \n      9\n      9\n      3.8\n      57190.0\n    \n    \n      10\n      10\n      4.0\n      63219.0\n    \n    \n      11\n      11\n      4.1\n      55795.0\n    \n    \n      12\n      12\n      4.1\n      56958.0\n    \n    \n      13\n      13\n      4.2\n      57082.0\n    \n    \n      14\n      14\n      4.6\n      61112.0\n    \n    \n      15\n      15\n      5.0\n      67939.0\n    \n    \n      16\n      16\n      5.2\n      66030.0\n    \n    \n      17\n      17\n      5.4\n      83089.0\n    \n    \n      18\n      18\n      6.0\n      81364.0\n    \n    \n      19\n      19\n      6.1\n      93941.0\n    \n    \n      20\n      20\n      6.9\n      91739.0\n    \n    \n      21\n      21\n      7.2\n      98274.0\n    \n    \n      22\n      22\n      8.0\n      101303.0\n    \n    \n      23\n      23\n      8.3\n      113813.0\n    \n    \n      24\n      24\n      8.8\n      109432.0\n    \n    \n      25\n      25\n      9.1\n      105583.0\n    \n    \n      26\n      26\n      9.6\n      116970.0\n    \n    \n      27\n      27\n      9.7\n      112636.0\n    \n    \n      28\n      28\n      10.4\n      122392.0\n    \n    \n      29\n      29\n      10.6\n      121873.0\n    \n  \n\n\n\n\n\nsalary.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 30 entries, 0 to 29\nData columns (total 3 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Unnamed: 0       30 non-null     int64  \n 1   YearsExperience  30 non-null     float64\n 2   Salary           30 non-null     float64\ndtypes: float64(2), int64(1)\nmemory usage: 848.0 bytes\n\n\n\n\n\nMelihat jumlah data null pada dataset\n\nsalary.isna().sum()\n\nUnnamed: 0         0\nYearsExperience    0\nSalary             0\ndtype: int64\n\n\nMelihat jumlah data duplikat pada dataset\n\nsalary.duplicated().sum()\n\n0\n\n\nMenghapus kolom ‘Unnamed :0’ dari DataFrame secara permanen\n\nsalary.drop('Unnamed: 0', axis=1, inplace=True)\n\n\nsalary\n\n\n\n\n\n  \n    \n      \n      YearsExperience\n      Salary\n    \n  \n  \n    \n      0\n      1.2\n      39344.0\n    \n    \n      1\n      1.4\n      46206.0\n    \n    \n      2\n      1.6\n      37732.0\n    \n    \n      3\n      2.1\n      43526.0\n    \n    \n      4\n      2.3\n      39892.0\n    \n    \n      5\n      3.0\n      56643.0\n    \n    \n      6\n      3.1\n      60151.0\n    \n    \n      7\n      3.3\n      54446.0\n    \n    \n      8\n      3.3\n      64446.0\n    \n    \n      9\n      3.8\n      57190.0\n    \n    \n      10\n      4.0\n      63219.0\n    \n    \n      11\n      4.1\n      55795.0\n    \n    \n      12\n      4.1\n      56958.0\n    \n    \n      13\n      4.2\n      57082.0\n    \n    \n      14\n      4.6\n      61112.0\n    \n    \n      15\n      5.0\n      67939.0\n    \n    \n      16\n      5.2\n      66030.0\n    \n    \n      17\n      5.4\n      83089.0\n    \n    \n      18\n      6.0\n      81364.0\n    \n    \n      19\n      6.1\n      93941.0\n    \n    \n      20\n      6.9\n      91739.0\n    \n    \n      21\n      7.2\n      98274.0\n    \n    \n      22\n      8.0\n      101303.0\n    \n    \n      23\n      8.3\n      113813.0\n    \n    \n      24\n      8.8\n      109432.0\n    \n    \n      25\n      9.1\n      105583.0\n    \n    \n      26\n      9.6\n      116970.0\n    \n    \n      27\n      9.7\n      112636.0\n    \n    \n      28\n      10.4\n      122392.0\n    \n    \n      29\n      10.6\n      121873.0\n    \n  \n\n\n\n\n\n\n\nMengubah setiap nilai di kolom Salary dan mengubah nama kolomnya di DataFrame secara permanen\n\nsalary['Salary'] = salary['Salary']/1000\nsalary.rename(columns={'Salary' : 'Salary (1000 $)'}, inplace=True)\n\nMelihat statistik deskriptif dari DataFrame\n\nsalary.describe()\n\n\n\n\n\n  \n    \n      \n      YearsExperience\n      Salary (1000 $)\n    \n  \n  \n    \n      count\n      30.000000\n      30.00000\n    \n    \n      mean\n      5.413333\n      76.00400\n    \n    \n      std\n      2.837888\n      27.41443\n    \n    \n      min\n      1.200000\n      37.73200\n    \n    \n      25%\n      3.300000\n      56.72175\n    \n    \n      50%\n      4.800000\n      65.23800\n    \n    \n      75%\n      7.800000\n      100.54575\n    \n    \n      max\n      10.600000\n      122.39200\n    \n  \n\n\n\n\n\nplt.scatter(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.plot(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.xlabel('Year Experience')\nplt.ylabel('Salary (1000 $)')\nplt.show()\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='Salary (1000 $)', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='Salary (1000 $)', ax=ax_hist, binwidth=10.)\nsns.rugplot(data=salary, x='Salary (1000 $)', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='YearsExperience', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='YearsExperience', ax=ax_hist, binwidth=1.)\nsns.rugplot(data=salary, x='YearsExperience', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\ncorr = salary.corr()\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\nplt.subplots(figsize=(6,6))\n\nsns.regplot(data = salary, x='YearsExperience', y='Salary (1000 $)', color='k', marker='+')\nplt.show()\n\n\n\n\n\n\n\nKarena pada dataset ini, fitur yang ada hanya 2, tidak ada masalah dan data sudah rapi, maka untuk step feature engineering akan skip dan lanjut ke tahap modelling.\n\n\n\n\nX = salary[['YearsExperience']]\ny = salary[['Salary (1000 $)']]\n\n\nX\n\n\n\n\n\n  \n    \n      \n      YearsExperience\n    \n  \n  \n    \n      0\n      1.2\n    \n    \n      1\n      1.4\n    \n    \n      2\n      1.6\n    \n    \n      3\n      2.1\n    \n    \n      4\n      2.3\n    \n    \n      5\n      3.0\n    \n    \n      6\n      3.1\n    \n    \n      7\n      3.3\n    \n    \n      8\n      3.3\n    \n    \n      9\n      3.8\n    \n    \n      10\n      4.0\n    \n    \n      11\n      4.1\n    \n    \n      12\n      4.1\n    \n    \n      13\n      4.2\n    \n    \n      14\n      4.6\n    \n    \n      15\n      5.0\n    \n    \n      16\n      5.2\n    \n    \n      17\n      5.4\n    \n    \n      18\n      6.0\n    \n    \n      19\n      6.1\n    \n    \n      20\n      6.9\n    \n    \n      21\n      7.2\n    \n    \n      22\n      8.0\n    \n    \n      23\n      8.3\n    \n    \n      24\n      8.8\n    \n    \n      25\n      9.1\n    \n    \n      26\n      9.6\n    \n    \n      27\n      9.7\n    \n    \n      28\n      10.4\n    \n    \n      29\n      10.6\n    \n  \n\n\n\n\n\ny\n\n\n\n\n\n  \n    \n      \n      Salary (1000 $)\n    \n  \n  \n    \n      0\n      39.344\n    \n    \n      1\n      46.206\n    \n    \n      2\n      37.732\n    \n    \n      3\n      43.526\n    \n    \n      4\n      39.892\n    \n    \n      5\n      56.643\n    \n    \n      6\n      60.151\n    \n    \n      7\n      54.446\n    \n    \n      8\n      64.446\n    \n    \n      9\n      57.190\n    \n    \n      10\n      63.219\n    \n    \n      11\n      55.795\n    \n    \n      12\n      56.958\n    \n    \n      13\n      57.082\n    \n    \n      14\n      61.112\n    \n    \n      15\n      67.939\n    \n    \n      16\n      66.030\n    \n    \n      17\n      83.089\n    \n    \n      18\n      81.364\n    \n    \n      19\n      93.941\n    \n    \n      20\n      91.739\n    \n    \n      21\n      98.274\n    \n    \n      22\n      101.303\n    \n    \n      23\n      113.813\n    \n    \n      24\n      109.432\n    \n    \n      25\n      105.583\n    \n    \n      26\n      116.970\n    \n    \n      27\n      112.636\n    \n    \n      28\n      122.392\n    \n    \n      29\n      121.873\n    \n  \n\n\n\n\nSplit dataset menjadi data train dan data test dengan komposisi pembagian yang sering digunakan\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n((24, 1), (6, 1), (24, 1), (6, 1))\n\n\nImport terlebih dahulu package yang akan digunakan untuk modelling\n\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\ny_pred = lr.predict(X_test)\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nprint(mean_squared_error(y_pred,y_test))\nprint(r2_score(y_pred,y_test))\n\n49.830096855908344\n0.8961838737587329\n\n\n \nDimana:\n\\(n\\) : jumlah data\n\\(Y_i\\) : nilai actual\n\\(\\hat{Y}_{i}\\): nilai predict\n\\(RSS\\) : sum of squared residuals\n\\(TSS\\) : total sum of squares\n\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n\n[[115.79121011 112.636     ]\n [ 71.49927809  67.939     ]\n [102.59786866 113.813     ]\n [ 75.26880422  83.089     ]\n [ 55.47879205  64.446     ]\n [ 60.19069971  57.19      ]]\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n\n\nheart = pd.read_csv('heart.csv')\nheart\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n      output\n    \n  \n  \n    \n      0\n      63\n      1\n      3\n      145\n      233\n      1\n      0\n      150\n      0\n      2.3\n      0\n      0\n      1\n      1\n    \n    \n      1\n      37\n      1\n      2\n      130\n      250\n      0\n      1\n      187\n      0\n      3.5\n      0\n      0\n      2\n      1\n    \n    \n      2\n      41\n      0\n      1\n      130\n      204\n      0\n      0\n      172\n      0\n      1.4\n      2\n      0\n      2\n      1\n    \n    \n      3\n      56\n      1\n      1\n      120\n      236\n      0\n      1\n      178\n      0\n      0.8\n      2\n      0\n      2\n      1\n    \n    \n      4\n      57\n      0\n      0\n      120\n      354\n      0\n      1\n      163\n      1\n      0.6\n      2\n      0\n      2\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      298\n      57\n      0\n      0\n      140\n      241\n      0\n      1\n      123\n      1\n      0.2\n      1\n      0\n      3\n      0\n    \n    \n      299\n      45\n      1\n      3\n      110\n      264\n      0\n      1\n      132\n      0\n      1.2\n      1\n      0\n      3\n      0\n    \n    \n      300\n      68\n      1\n      0\n      144\n      193\n      1\n      1\n      141\n      0\n      3.4\n      1\n      2\n      3\n      0\n    \n    \n      301\n      57\n      1\n      0\n      130\n      131\n      0\n      1\n      115\n      1\n      1.2\n      1\n      1\n      3\n      0\n    \n    \n      302\n      57\n      0\n      1\n      130\n      236\n      0\n      0\n      174\n      0\n      0.0\n      1\n      1\n      2\n      0\n    \n  \n\n303 rows × 14 columns\n\n\n\n\n# Membaca .txt tentang kolom - kolom dataset yang diberikan pada soal\nwith open('about dataset.txt', 'r') as f:\n  print(f.read())\n\nAbout datasets\n1. age - age in years \n2. sex - sex (1 = male; 0 = female) \n3. cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 0 = asymptomatic) \n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) \n5. chol - serum cholestoral in mg/dl \n6. fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false) \n7. restecg - resting electrocardiographic results (1 = normal; 2 = having ST-T wave abnormality; 0 = hypertrophy) \n8. thalach - maximum heart rate achieved \n9. exang - exercise induced angina (1 = yes; 0 = no) \n10. oldpeak - ST depression induced by exercise relative to rest \n11. slope - the slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping) \n12. ca - number of major vessels (0-3) colored by flourosopy \n13. thal - 2 = normal; 1 = fixed defect; 3 = reversable defect \n14. output - the predicted attribute - diagnosis of heart disease (0 = less chance of heart attack, 1 = higher chance of heart attack)\n\n\n\n\nheart.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 303 entries, 0 to 302\nData columns (total 14 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       303 non-null    int64  \n 1   sex       303 non-null    int64  \n 2   cp        303 non-null    int64  \n 3   trtbps    303 non-null    int64  \n 4   chol      303 non-null    int64  \n 5   fbs       303 non-null    int64  \n 6   restecg   303 non-null    int64  \n 7   thalachh  303 non-null    int64  \n 8   exng      303 non-null    int64  \n 9   oldpeak   303 non-null    float64\n 10  slp       303 non-null    int64  \n 11  caa       303 non-null    int64  \n 12  thall     303 non-null    int64  \n 13  output    303 non-null    int64  \ndtypes: float64(1), int64(13)\nmemory usage: 33.3 KB\n\n\n\nheart.output.value_counts()\n\n1    165\n0    138\nName: output, dtype: int64\n\n\n\n\n\n\nheart.describe()\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n      output\n    \n  \n  \n    \n      count\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n    \n    \n      mean\n      54.366337\n      0.683168\n      0.966997\n      131.623762\n      246.264026\n      0.148515\n      0.528053\n      149.646865\n      0.326733\n      1.039604\n      1.399340\n      0.729373\n      2.313531\n      0.544554\n    \n    \n      std\n      9.082101\n      0.466011\n      1.032052\n      17.538143\n      51.830751\n      0.356198\n      0.525860\n      22.905161\n      0.469794\n      1.161075\n      0.616226\n      1.022606\n      0.612277\n      0.498835\n    \n    \n      min\n      29.000000\n      0.000000\n      0.000000\n      94.000000\n      126.000000\n      0.000000\n      0.000000\n      71.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      47.500000\n      0.000000\n      0.000000\n      120.000000\n      211.000000\n      0.000000\n      0.000000\n      133.500000\n      0.000000\n      0.000000\n      1.000000\n      0.000000\n      2.000000\n      0.000000\n    \n    \n      50%\n      55.000000\n      1.000000\n      1.000000\n      130.000000\n      240.000000\n      0.000000\n      1.000000\n      153.000000\n      0.000000\n      0.800000\n      1.000000\n      0.000000\n      2.000000\n      1.000000\n    \n    \n      75%\n      61.000000\n      1.000000\n      2.000000\n      140.000000\n      274.500000\n      0.000000\n      1.000000\n      166.000000\n      1.000000\n      1.600000\n      2.000000\n      1.000000\n      3.000000\n      1.000000\n    \n    \n      max\n      77.000000\n      1.000000\n      3.000000\n      200.000000\n      564.000000\n      1.000000\n      2.000000\n      202.000000\n      1.000000\n      6.200000\n      2.000000\n      4.000000\n      3.000000\n      1.000000\n    \n  \n\n\n\n\n\npd.plotting.scatter_matrix(heart[['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']], figsize=(15,12)) # plot data yang numerik dan kontinu\nplt.show()\n\n\n\n\nPlot diatas saya ingin melihat korelasi secara kasar antara fitur - fitur yang numerik dan kontinu, melalui scatter plot, serta range nilai datanya melalui histogramnya.\nMelalui scatter plot dapat kita lihat bahwa kita belum bisa menyimpulkan korelasi antara fitur - fitur, karena persebarannya sebagian besar sangat acak. Melalui histogram dapat dilihat bahwa range nilainya cukup berjauhan (oldpeak 0 sampai 6, sedangkan chol 100 sampai 500+), sehingga perlu dilakukan standarisasi pada data numerik nantinya dengan StandardScaler\n\ncorr = heart.corr()\nplt.subplots(figsize=(10,10))\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\n\n\n\nX = heart.drop('output',axis=1).copy()\ny = heart.iloc[:,[-1]]\n\n\nX\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n    \n  \n  \n    \n      0\n      63\n      1\n      3\n      145\n      233\n      1\n      0\n      150\n      0\n      2.3\n      0\n      0\n      1\n    \n    \n      1\n      37\n      1\n      2\n      130\n      250\n      0\n      1\n      187\n      0\n      3.5\n      0\n      0\n      2\n    \n    \n      2\n      41\n      0\n      1\n      130\n      204\n      0\n      0\n      172\n      0\n      1.4\n      2\n      0\n      2\n    \n    \n      3\n      56\n      1\n      1\n      120\n      236\n      0\n      1\n      178\n      0\n      0.8\n      2\n      0\n      2\n    \n    \n      4\n      57\n      0\n      0\n      120\n      354\n      0\n      1\n      163\n      1\n      0.6\n      2\n      0\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      298\n      57\n      0\n      0\n      140\n      241\n      0\n      1\n      123\n      1\n      0.2\n      1\n      0\n      3\n    \n    \n      299\n      45\n      1\n      3\n      110\n      264\n      0\n      1\n      132\n      0\n      1.2\n      1\n      0\n      3\n    \n    \n      300\n      68\n      1\n      0\n      144\n      193\n      1\n      1\n      141\n      0\n      3.4\n      1\n      2\n      3\n    \n    \n      301\n      57\n      1\n      0\n      130\n      131\n      0\n      1\n      115\n      1\n      1.2\n      1\n      1\n      3\n    \n    \n      302\n      57\n      0\n      1\n      130\n      236\n      0\n      0\n      174\n      0\n      0.0\n      1\n      1\n      2\n    \n  \n\n303 rows × 13 columns\n\n\n\n\ny\n\n\n\n\n\n  \n    \n      \n      output\n    \n  \n  \n    \n      0\n      1\n    \n    \n      1\n      1\n    \n    \n      2\n      1\n    \n    \n      3\n      1\n    \n    \n      4\n      1\n    \n    \n      ...\n      ...\n    \n    \n      298\n      0\n    \n    \n      299\n      0\n    \n    \n      300\n      0\n    \n    \n      301\n      0\n    \n    \n      302\n      0\n    \n  \n\n303 rows × 1 columns\n\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nheart.columns\n\nIndex(['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n       'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output'],\n      dtype='object')\n\n\n\nsc = StandardScaler()\ncol = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nX_train.loc[:,col] = sc.fit_transform(X_train.loc[:,col])\n\n\nX_train\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n    \n  \n  \n    \n      132\n      -1.356798\n      1\n      1\n      -0.616856\n      0.914034\n      0\n      1\n      0.532781\n      0\n      -0.920864\n      2\n      0\n      2\n    \n    \n      202\n      0.385086\n      1\n      0\n      1.169491\n      0.439527\n      0\n      0\n      -1.753582\n      1\n      -0.193787\n      2\n      0\n      3\n    \n    \n      196\n      -0.921327\n      1\n      2\n      1.169491\n      -0.300704\n      0\n      1\n      -0.139679\n      0\n      2.350982\n      1\n      0\n      2\n    \n    \n      75\n      0.058483\n      0\n      1\n      0.276318\n      0.059921\n      0\n      0\n      0.487950\n      0\n      0.351521\n      1\n      0\n      2\n    \n    \n      176\n      0.602822\n      1\n      0\n      -0.795490\n      -0.319684\n      1\n      1\n      0.443119\n      1\n      0.351521\n      2\n      2\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      188\n      -0.485856\n      1\n      2\n      0.574042\n      -0.262744\n      0\n      1\n      0.577611\n      0\n      -0.375556\n      1\n      1\n      3\n    \n    \n      71\n      -0.376988\n      1\n      2\n      -2.165023\n      -0.376625\n      0\n      1\n      0.174136\n      1\n      -0.920864\n      2\n      1\n      3\n    \n    \n      106\n      1.582631\n      1\n      3\n      1.764940\n      -0.243763\n      1\n      0\n      -0.856969\n      0\n      -0.829979\n      1\n      1\n      2\n    \n    \n      270\n      -0.921327\n      1\n      0\n      -0.616856\n      0.040941\n      0\n      0\n      -0.274171\n      0\n      -0.193787\n      2\n      0\n      3\n    \n    \n      102\n      0.929425\n      0\n      1\n      0.574042\n      -0.983994\n      0\n      1\n      1.294902\n      0\n      -0.920864\n      2\n      2\n      2\n    \n  \n\n242 rows × 13 columns\n\n\n\n\nX_test.loc[:,col] = sc.transform(X_test.loc[:,col])\nX_test\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n    \n  \n  \n    \n      179\n      0.276218\n      1\n      0\n      1.169491\n      0.553408\n      0\n      0\n      -1.708752\n      1\n      -0.375556\n      1\n      1\n      1\n    \n    \n      228\n      0.493954\n      1\n      3\n      2.360389\n      0.781172\n      0\n      0\n      0.398289\n      0\n      -0.739095\n      1\n      0\n      3\n    \n    \n      111\n      0.276218\n      1\n      2\n      1.169491\n      -2.293633\n      1\n      1\n      1.025918\n      0\n      -0.739095\n      2\n      1\n      3\n    \n    \n      246\n      0.167350\n      0\n      0\n      0.216773\n      3.077785\n      0\n      0\n      -0.005187\n      1\n      0.805944\n      1\n      2\n      3\n    \n    \n      60\n      1.800367\n      0\n      2\n      -1.212304\n      0.344625\n      1\n      0\n      -0.901800\n      0\n      -0.920864\n      2\n      1\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      249\n      1.582631\n      1\n      2\n      0.574042\n      0.135842\n      0\n      0\n      -0.184510\n      0\n      0.896828\n      1\n      3\n      3\n    \n    \n      104\n      -0.485856\n      1\n      2\n      -0.080952\n      -0.965014\n      0\n      1\n      0.577611\n      0\n      -0.920864\n      2\n      0\n      2\n    \n    \n      300\n      1.473764\n      1\n      0\n      0.812222\n      -1.021955\n      1\n      1\n      -0.408663\n      0\n      2.169213\n      1\n      2\n      3\n    \n    \n      193\n      0.602822\n      1\n      0\n      0.871767\n      0.667290\n      0\n      0\n      -0.363832\n      1\n      1.623905\n      1\n      2\n      3\n    \n    \n      184\n      -0.485856\n      1\n      0\n      1.169491\n      -0.072941\n      0\n      0\n      -0.991461\n      0\n      1.442136\n      1\n      0\n      3\n    \n  \n\n61 rows × 13 columns\n\n\n\n\n\n\n\nlog_regr = LogisticRegression()\nsvc = SVC()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\n\n\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# melakukan cross validation pada masing-masing metode\nlr_score = cross_val_score(log_regr, X_train, y_train, cv=kfold, scoring='f1').mean()\nsvc_score = cross_val_score(svc, X_train, y_train, cv=kfold, scoring='f1').mean()\ndt_score = cross_val_score(dt, X_train, y_train, cv=kfold, scoring='f1').mean()\nrf_score = cross_val_score(rf, X_train, y_train, cv=kfold, scoring='f1').mean()\n\n\nfor i in [lr_score, svc_score, dt_score, rf_score]:\n    print(i)\n\n0.838821143443002\n0.8530945548368415\n0.7278904812545365\n0.8365591551305837\n\n\n\n\n\n\nparams = {'C':[0.01,0.05,0.1,0.7,0.5,1,5,10,50,100],     # hyperparameter yang akan dievaluasi untuk SVC\n             'kernel':['poly','rbf']}\n\ngrid_search = GridSearchCV(svc, params, cv=kfold, scoring='f1')\ngrid_search.fit(X_train,y_train)\n\n\ngrid_search.best_params_, grid_search.cv_results_['mean_test_score'].max()\n\n({'C': 0.7, 'kernel': 'rbf'}, 0.8596614105205573)\n\n\n\nmodel = grid_search.best_estimator_\nmodel.fit(X_train,y_train)\n\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n\n\nSVC(C=0.7)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVCSVC(C=0.7)\n\n\n\ny_pred = model.predict(X_test)\ny_pred\n\narray([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)\n\n\n\n\n\n\nf1_score(y_test,y_pred)\n\n0.8923076923076922\n\n\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\ndef evaluation_parametrics(name,y_val, y_pred):\n    \n    print(\"\\n------------------------{}------------------------\\n\".format(name))\n\n    cm_test = confusion_matrix(y_val, y_pred)\n    t1 = ConfusionMatrixDisplay(cm_test)    \n    print(\"\\nClassification Report for Data Test\\n\")\n    print(classification_report(y_val, y_pred))   \n    print(\"--------------------------------------------------------------------------\")\n\n    t1.plot()\n\n\nevaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred)\n\n\n------------------------Machine Learning - Classification------------------------\n\n\nClassification Report for Data Test\n\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.88        29\n           1       0.88      0.91      0.89        32\n\n    accuracy                           0.89        61\n   macro avg       0.89      0.88      0.88        61\nweighted avg       0.89      0.89      0.89        61\n\n--------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nimage.png\n\n\nPerbandingan data actual dan data prediksi\n\nprint(np.concatenate((y_test.values.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1)),1))\n\n[[0 0]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [0 0]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [0 0]]\n\n\n\n\n\n\nfrom sklearn.inspection import permutation_importance\nresult = permutation_importance(model, X_test, y_test, n_repeats=10,\n                                scoring='f1', random_state=42)\n\n\nresult_sorted = []\ncolumns_sorted = []\n\nfor res, col in sorted(zip(result.importances_mean, X_test.columns.values), reverse=True):\n  result_sorted.append(res)\n  columns_sorted.append(col)\n\nsns.barplot(x = result_sorted, y = columns_sorted)\nplt.show()\n\n\n\n\n\n\n\nSimpan model ke dalam file dan model siap digunakan untuk predict\n\nimport joblib\njoblib.dump(model,'model_SVC.pkl')\n\n['model_SVC.pkl']"
  },
  {
    "objectID": "main-module/week-05.html",
    "href": "main-module/week-05.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "# TODO\n- [ ] keras explanation\n- [ ] tambahin kata-kata penjelas"
  },
  {
    "objectID": "main-module/week-05.html#prerequisites",
    "href": "main-module/week-05.html#prerequisites",
    "title": "sains-data-2023",
    "section": "prerequisites",
    "text": "prerequisites\n\n# !pip install tensorflow # uncomment if you don't have tensorflow installed\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np"
  },
  {
    "objectID": "main-module/week-05.html#all-about-tensors-and-tensorflow",
    "href": "main-module/week-05.html#all-about-tensors-and-tensorflow",
    "title": "sains-data-2023",
    "section": "All about Tensors and Tensorflow",
    "text": "All about Tensors and Tensorflow\n\n# All-ones or all-zeros tensors\n\nx = tf.ones(shape = (2,1)) # 2x3 matrix of ones, similar to np.ones((2,1))\nprint(x)\n\nx = tf.zeros(shape = (2,1)) # 2x3 matrix of zeros, similar to np.zeros((2,1))\nprint(x)\n\n\ntf.Tensor(\n[[1.]\n [1.]], shape=(2, 1), dtype=float32)\ntf.Tensor(\n[[0.]\n [0.]], shape=(2, 1), dtype=float32)\n\n\n\nx.__class__\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n# Random tensors\n\n# create a tensor with random values from a normal distribution\nx = tf.random.normal(shape = (2,3), mean = 0, stddev = 1)\nprint(x)\n\n# create a tensor with random values from a uniform distribution\nx = tf.random.uniform(shape = (2,3), minval = 0, maxval = 1)\nprint(x)\n\ntf.Tensor(\n[[ 1.1509199  -1.4267175  -0.48263487]\n [-0.30107084  0.90581864  1.0413685 ]], shape=(2, 3), dtype=float32)\ntf.Tensor(\n[[0.6582366  0.34180927 0.91947365]\n [0.5607337  0.9532844  0.31796992]], shape=(2, 3), dtype=float32)\n\n\n\n# numpy array are assignable while tensors are not\nx = np.random.normal(loc = 0, scale = 1, size = (2,3))\nx[0,0] = 100\nprint(x)\n\n[[ 1.00000000e+02 -1.25304057e+00 -1.18967720e+00]\n [ 4.74877369e-01 -8.13430401e-02 -4.57822064e-01]]\n\n\n\n# numpy array are assignable while tensors are not\nx = tf.ones(shape = (2,3))\nx[0,0] = 100\nprint(x)\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\n# Creating a TensorFlow variable\nv = tf.Variable(initial_value = tf.random.normal(shape = (2,3)))\nprint(v)\nprint()\n\nv.assign(tf.zeros(shape = (2,3)))\nprint(v)\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[-0.10799041,  2.325188  , -0.20042379],\n       [ 0.48759696,  0.53195345,  0.29525948]], dtype=float32)>\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)>\n\n\n\n# Assigning a value to a subset of a TensorFlow variable\nv[0,0].assign(100)\nprint(v)\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[100.,   0.,   0.],\n       [  0.,   0.,   0.]], dtype=float32)>\n\n\n\n# Assign add\nv.assign_add(tf.ones(shape = (2,3)))\nprint(v)\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[101.,   1.,   1.],\n       [  1.,   1.,   1.]], dtype=float32)>\n\n\n\n# just like numpy, TensorFlow offers a large collection of tensor operations to express\n# mathematical formulas.\na = tf.ones((2, 2))\nb = tf.square(a)\nc = tf.sqrt(a)\nd = b + c\ne = tf.matmul(a, b)\ne *= d\nprint(e)\n\ntf.Tensor(\n[[4. 4.]\n [4. 4.]], shape=(2, 2), dtype=float32)\n\n\nSo far, TensorFlow seems to look a lot like NumPy. But here’s something NumPy can’t do: retrieve the gradient of any differentiable expression with respect to any of its inputs. Just open a GradientTape scope, apply some computation to one or several input tensors, and retrieve the gradient of the result with respect to the inputs\n\n# Using the GradientTape\ninput_var = tf.Variable(initial_value = 3.0)\nwith tf.GradientTape() as tape:\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using GradientTape with constant tensor inputs\ninput_var = tf.constant(3.0)\nwith tf.GradientTape() as tape:\n    tape.watch(input_var)\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using nested gradient tapes to compute second-order gradients\ntime = tf.Variable(0.0)\nwith tf.GradientTape() as outer_tape:\n    with tf.GradientTape() as inner_tape:\n        position = 4.9 * time ** 2\n    speed = inner_tape.gradient(position, time) \nacceleration = outer_tape.gradient(speed, time)\n\nprint(speed)\nprint(acceleration)\n\n\ntf.Tensor(0.0, shape=(), dtype=float32)\ntf.Tensor(9.8, shape=(), dtype=float32)"
  },
  {
    "objectID": "main-module/week-05.html#an-end-to-end-example-a-linear-classifier-in-pure-tensorflow",
    "href": "main-module/week-05.html#an-end-to-end-example-a-linear-classifier-in-pure-tensorflow",
    "title": "sains-data-2023",
    "section": "An end-to-end example: A linear classifier in pure TensorFlow",
    "text": "An end-to-end example: A linear classifier in pure TensorFlow\n\n# Generating two classes of random points in a 2D plane\nnum_samples_per_class, num_classes = 1000, 2\nnegative_samples = np.random.multivariate_normal(mean = [0,3], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\npositive_samples = np.random.multivariate_normal(mean = [3,0], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\n\ninputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\ntargets = np.vstack((np.zeros((num_samples_per_class, 1), dtype = 'float32'), np.ones((num_samples_per_class, 1), dtype = 'float32')))\n\n\nimport matplotlib.pyplot as plt\nplt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\nplt.show()\n\n\n\n\n\n# Creating the linear classifier variables\ninput_dim = 2\noutput_dim = 1\nW = tf.Variable(tf.random.normal(shape = (input_dim, output_dim)))\nb = tf.Variable(tf.random.normal(shape = (output_dim,)))\n\n\n\n# the forward pass\ndef model(inputs):\n    return tf.sigmoid(tf.matmul(inputs, W) + b)\n    \n# The mean squared error loss function\n\ndef entropy_loss(targets, predictions):\n    per_sample_losses = - targets * tf.math.log(predictions) - (1 - targets) * tf.math.log(1 - predictions)\n    return tf.reduce_mean(per_sample_losses)\n\n\n# training step \nlearning_rate = 0.1\ndef training_step(inputs, targets):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = square_loss(targets, predictions)\n        grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n        W.assign_sub(learning_rate * grad_loss_wrt_W)\n        b.assign_sub(learning_rate * grad_loss_wrt_b)\n        return loss\n\n\n\n\n\n# training loop/process/epoch\nfor step in range(100):\n    loss = training_step(inputs, targets)\n    print(f\"Loss at step {step}: {loss:.4f}\")\n\nLoss at step 0: 0.0495\nLoss at step 1: 0.0473\nLoss at step 2: 0.0454\nLoss at step 3: 0.0436\nLoss at step 4: 0.0420\nLoss at step 5: 0.0406\nLoss at step 6: 0.0392\nLoss at step 7: 0.0380\nLoss at step 8: 0.0369\nLoss at step 9: 0.0358\nLoss at step 10: 0.0348\nLoss at step 11: 0.0339\nLoss at step 12: 0.0330\nLoss at step 13: 0.0322\nLoss at step 14: 0.0315\nLoss at step 15: 0.0308\nLoss at step 16: 0.0301\nLoss at step 17: 0.0295\nLoss at step 18: 0.0289\nLoss at step 19: 0.0283\nLoss at step 20: 0.0278\nLoss at step 21: 0.0273\nLoss at step 22: 0.0268\nLoss at step 23: 0.0263\nLoss at step 24: 0.0259\nLoss at step 25: 0.0255\nLoss at step 26: 0.0251\nLoss at step 27: 0.0247\nLoss at step 28: 0.0243\nLoss at step 29: 0.0240\nLoss at step 30: 0.0236\nLoss at step 31: 0.0233\nLoss at step 32: 0.0230\nLoss at step 33: 0.0227\nLoss at step 34: 0.0224\nLoss at step 35: 0.0221\nLoss at step 36: 0.0218\nLoss at step 37: 0.0215\nLoss at step 38: 0.0213\nLoss at step 39: 0.0210\nLoss at step 40: 0.0208\nLoss at step 41: 0.0205\nLoss at step 42: 0.0203\nLoss at step 43: 0.0201\nLoss at step 44: 0.0198\nLoss at step 45: 0.0196\nLoss at step 46: 0.0194\nLoss at step 47: 0.0192\nLoss at step 48: 0.0190\nLoss at step 49: 0.0188\nLoss at step 50: 0.0186\nLoss at step 51: 0.0185\nLoss at step 52: 0.0183\nLoss at step 53: 0.0181\nLoss at step 54: 0.0179\nLoss at step 55: 0.0178\nLoss at step 56: 0.0176\nLoss at step 57: 0.0174\nLoss at step 58: 0.0173\nLoss at step 59: 0.0171\nLoss at step 60: 0.0170\nLoss at step 61: 0.0168\nLoss at step 62: 0.0167\nLoss at step 63: 0.0166\nLoss at step 64: 0.0164\nLoss at step 65: 0.0163\nLoss at step 66: 0.0162\nLoss at step 67: 0.0160\nLoss at step 68: 0.0159\nLoss at step 69: 0.0158\nLoss at step 70: 0.0157\nLoss at step 71: 0.0155\nLoss at step 72: 0.0154\nLoss at step 73: 0.0153\nLoss at step 74: 0.0152\nLoss at step 75: 0.0151\nLoss at step 76: 0.0150\nLoss at step 77: 0.0149\nLoss at step 78: 0.0148\nLoss at step 79: 0.0147\nLoss at step 80: 0.0146\nLoss at step 81: 0.0145\nLoss at step 82: 0.0144\nLoss at step 83: 0.0143\nLoss at step 84: 0.0142\nLoss at step 85: 0.0141\nLoss at step 86: 0.0140\nLoss at step 87: 0.0139\nLoss at step 88: 0.0138\nLoss at step 89: 0.0137\nLoss at step 90: 0.0136\nLoss at step 91: 0.0135\nLoss at step 92: 0.0135\nLoss at step 93: 0.0134\nLoss at step 94: 0.0133\nLoss at step 95: 0.0132\nLoss at step 96: 0.0131\nLoss at step 97: 0.0131\nLoss at step 98: 0.0130\nLoss at step 99: 0.0129\n\n\n\npredictions = model(inputs)\nprint(predictions)\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)\nplt.show()\n\ntf.Tensor(\n[[0.04117302]\n [0.02456259]\n [0.00931301]\n ...\n [0.9823857 ]\n [0.9144001 ]\n [0.98359877]], shape=(2000, 1), dtype=float32)"
  },
  {
    "objectID": "tugas/tugas-2.html",
    "href": "tugas/tugas-2.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "Kerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas2PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas2PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-02\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Carles_Octavianus (carles)\n\n\n\n\n\n[akses-data]: https://drive.google.com/open?id=1whKzd5rd-Rtg8bGmEYeBonsXLQMKfxTB&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk memprediksi harga rumah berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model regresi)."
  },
  {
    "objectID": "tugas/tugas-3.html",
    "href": "tugas/tugas-3.html",
    "title": "sains-data-2023",
    "section": "",
    "text": "Kerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas3PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas3PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-03\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Tulus Setiawan (WA/LINE: tlsnew/081213679316)\n\n\n\n\n\n[akses-data]: https://drive.google.com/open?id=19WogXg2YgH7tNhAXESJ7SaITOWGGu2HX&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk mengklasifikasikan harga ponsel berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model Klasifikasi)."
  }
]